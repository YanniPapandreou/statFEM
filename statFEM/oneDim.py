# AUTOGENERATED! DO NOT EDIT! File to edit: 00_oneDim.ipynb (unless otherwise specified).

__all__ = ['mean_assembler', 'kernMat', 'BigPhiMat', 'cov_assembler', 'm_post', 'sample_gp', 'gen_sensor',
           'MyExpression']

# Cell
from dolfin import *
import numpy as np
from scipy import integrate
from scipy.spatial.distance import cdist
from scipy.linalg import sqrtm
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import spsolve
from scipy.interpolate import interp1d
from joblib import Parallel, delayed
import multiprocessing

# code to assemble the mean for a given mesh size
def mean_assembler(h,f_bar):
    "This function assembles the mean for the FEM prior for our 1-D problem"
    # get size of the grid
    J = int(np.round(1/h))

    # set up the mesh and function space for FEM
    mesh = UnitIntervalMesh(J)
    V = FunctionSpace(mesh,'Lagrange',1)

    # set up boundary conditiond
    def boundary(x, on_boundary):
        return on_boundary

    bc = DirichletBC(V, 0.0, boundary)
    # set up the functions p and f
    p = Constant(1.0)
    f = f_bar

    # set up the bilinear form for the variational problem
    u = TrialFunction(V)
    v = TestFunction(V)
    a = inner(p*grad(u),grad(v))*dx

    # set up the linear form
    L = f*v*dx

    # solve the variational problem
    μ = Function(V)
    solve(a == L, μ, bc)

    return μ

# Cell
def kernMat(k,grid,parallel=True,translation_inv = False):
    "Function to compute the covariance matrix K corresponding to the covariance kernel k on a grid. This matrix has ijth entry K_ij=k(x_i,x_j) where x_i is the ith point of the grid."
    # get the length of the grid
    n = len(grid)
    # preallocate an n x n array of zeros to hold the cov matrix
    K = np.zeros((n,n))

    # check if the cov matrix should be computed in parallel
    if parallel:
        # compute the cov matrix in parallel by computing the upper triangular part column by column
        # set up function to compute the ith column of the upper triangular part:
        def processInput(i):
            return np.array([k(grid[i],grid[j]) for j in range(i,n)])

        # get the number of cpu cores present and compute the upper triangular columns in parallel
        num_cores = multiprocessing.cpu_count()
        results = Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in range(n))

        # store the results in the appropriate positions in K
        #for (i,v) in enumerate(results[0:n-1]):
        for (i,v) in enumerate(results):  # is this correct???
            K[i,i:] = v

        # only the upper triangular part has been formed, so use the symmetry of the cov mat to get full K:
        K = K + K.T - np.diag(K.diagonal())
        return K
    elif translation_inv:
        # reshape grid so that it has correct dimensions
        grid = grid.reshape(n,1)

        # compute the distance matrix D
        D = cdist(grid,grid)

        # evaluate the kernel function using D
        K = k(D)
        return K
    else:
        for i in range(n):
            for j in range(i,n):
                K[i,j] = k(grid[i],grid[j])
        K = K + K.T - np.diag(K.diagonal())
        return K

# Cell
def BigPhiMat(J,grid):
    "Function to compute the Phi matrix."
    # create the FEM mesh and function space
    mesh = UnitIntervalMesh(J)
    V = FunctionSpace(mesh,'Lagrange',1)
    # get the tree for the mesh
    tree = mesh.bounding_box_tree()
    # set up a function to compute the ith column of Phi corresponding to the ith grid point
    def Φ(i):
        x = grid[i]
        cell_index = tree.compute_first_entity_collision(Point(x))
        cell = Cell(mesh,cell_index)
        cell_global_dofs = V.dofmap().cell_dofs(cell_index)
        vertex_coordinates = cell.get_vertex_coordinates()
        cell_orientation = cell.orientation()
        data = V.element().evaluate_basis_all(x,vertex_coordinates,cell_orientation)
        return (data,cell_global_dofs,i*np.ones_like(cell_global_dofs))
    # compute all the columns of Phi using the function above
    res = [Φ(i) for i in range(len(grid))]
    # assemble the sparse matrix Phi using the results
    data = np.hstack([res[i][0] for i in range(len(grid))])
    row = np.hstack([res[i][1] for i in range(len(grid))])
    col = np.hstack([res[i][2] for i in range(len(grid))])
    return csr_matrix((data,(row,col)),shape=(V.dim(),len(grid)))

# Cell
def cov_assembler(J,k_f,grid,parallel,translation_inv):
    "Function to assemble the approximate FEM covariance matrix on the reference grid."

    # set up mesh and function space
    mesh = UnitIntervalMesh(J)
    V = FunctionSpace(mesh,'Lagrange',1)

    # set up FE grid
    x_grid = V.tabulate_dof_coordinates()

    # set up boundary condition
    def boundary(x, on_boundary):
        return on_boundary

    bc = DirichletBC(V, 0.0, boundary)

    # get the boundary and interior dofs
    bc_dofs = bc.get_boundary_values().keys()
    first, last = V.dofmap().ownership_range()
    all_dofs = range(last - first)
    interior_dofs = list(set(all_dofs) - set(bc_dofs))
    bc_dofs = list(set(bc_dofs))

    # set up the function p
    p = Constant(1.0)

    # get the mass and stiffness matrices as sparse csr_matrics
    u = TrialFunction(V)
    v = TestFunction(V)

    mass_form = u*v*dx
    a = inner(p*grad(u),grad(v))*dx

    M = assemble(mass_form)
    A = assemble(a)
    M = as_backend_type(M).mat()
    A = as_backend_type(A).mat()
    M = csr_matrix(M.getValuesCSR()[::-1],shape=M.size)
    A = csr_matrix(A.getValuesCSR()[::-1],shape=A.size)

    # extract the submatrices corresponding to the interior dofs
    M = M[interior_dofs,:][:,interior_dofs]
    A = A[interior_dofs,:][:,interior_dofs]

    # get the forcing cov matrix on the interior nodes of the grid
    Σ_int = kernMat(k_f,x_grid[interior_dofs],parallel,translation_inv)

    # form the matrix B in the defintion of the approximate FEM cov mat
    # Note: overwrite Σ_int for memory efficiency.
#     Σ_int = M @ Σ_int @ M.T
    Σ_int = Σ_int @ M.T
    Σ_int = M @ Σ_int

    # form B (storing this in Σ_int directly for memory efficiency)
    Σ_int = spsolve(A,Σ_int)
    Σ_int = spsolve(A,Σ_int.T).T

    # ensure Σ_int is symmetric
    Σ_int = 0.5*(Σ_int + Σ_int.T)

    # get big phi matrix on the grid (extracting only the rows corresponding to the
    # interior dofs)
    Phi = BigPhiMat(J,grid)[interior_dofs,:]

    # assemble cov mat on grid using Phi and Σ_int
    Σ = Phi.T @ Σ_int @ Phi

    # ensure Σ is symmetric and return
    Σ = 0.5*(Σ + Σ.T)
    return Σ

# Cell
def m_post(x,m,c,v,Y,B):
    "This function evalutes the posterior mean at the point x."
    m_vect = np.array([m(y_i) for y_i in Y]).flatten()
    c_vect = c(x).flatten()

    # compute the update term
    update = c_vect @ np.linalg.solve(B,m_vect-v)

    # return m_post
    return (m(x) - update)

# Cell
def sample_gp(n_sim,m,k,grid,par=False,trans=True, tol=1e-9):
    "Function to sample a GP with mean m and cov k on a grid."
    # get length of grid
    d = len(grid)

    # construct mean vector
    μ = np.array([m(x) for x in grid]).reshape(d,1)

    # construct covariance matrix
    Σ = kernMat(k,grid,parallel = par, translation_inv = trans)

    # construct the cholesky decomposition Σ = GG^T
    # we add a small diagonal perturbation to Σ to ensure it
    # strictly positive definite
    G = np.linalg.cholesky(Σ + tol * np.eye(d))

    # draw iid standard normal random vectors
    Z = np.random.normal(size=(d,n_sim))

    # construct samples from GP(m,k)
    Y = G@Z + np.tile(μ,n_sim)
    # return the sampled trajectory
    return Y

# Cell
def gen_sensor(ϵ,m,k,Y,u_quad,grid,par=False,trans=True,tol=1e-9,maxiter=50,require_f=False):
    "Function to generate noisy sensor observations of the solution u on a sensor grid Y."

    # get number of sensors from the sensor grid Y
    s = len(Y)

    # sample a single f on the grid
    f_sim = sample_gp(1,m,k,grid,par=par,trans=trans,tol=tol)

    # create solution function
    # interpolate f to get a function
    f = interp1d(grid,f_sim.flatten(),kind='cubic')
    # use u_quad together with f to compute solution
    def u(x):
        return u_quad(x,f,maxiter=maxiter)

    # get solution on grid Y:
    u_Y = np.array([u(y_i) for y_i in Y])

    # add N(0,ϵ^2) to each evaluation point
    u_S = u_Y + ϵ*np.random.normal(size=s)

    # if require the simulated trajectory of f return this as well, if not just return u_S
    if require_f:
        return u_S, f_sim
    else:
        return u_S

# Cell
class MyExpression(UserExpression):
    "Class to allow users to user their own functions to create a FEniCS UserExpression."
    def eval(self, value, x):
        value[0] = self.f(x)
    def value_shape(self):
        return ()